{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e810749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 4.2.2\n",
      "Apache Spark version: 3.3.1\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "spark = sparknlp.start() \n",
    "# sparknlp.start(gpu=True) >> for training on GPUfrom sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f12d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41d44868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c9fa35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+--------+\n",
      "|                     description|category|\n",
      "+--------------------------------+--------+\n",
      "|           i want to make coffee|      DA|\n",
      "|                      where am i|      LR|\n",
      "|              what can i do here|      AR|\n",
      "|                    prepare meal|      DA|\n",
      "|                use refrigerator|      DA|\n",
      "|                         use fan|      DA|\n",
      "|                        use oven|      DA|\n",
      "|                       use stove|      DA|\n",
      "|     i would like to wash sheets|      DA|\n",
      "|i would like to watch television|      DA|\n",
      "+--------------------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDataset = spark.read \\\n",
    "      .option(\"header\", True) \\\n",
    "      .csv(\"text_train.csv\")\n",
    "trainDataset.show(10, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "25422e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+--------+\n",
      "|                     description|category|\n",
      "+--------------------------------+--------+\n",
      "|           i want to make coffee|      DA|\n",
      "|                      where am i|      LR|\n",
      "|              what can i do here|      AR|\n",
      "|                    prepare meal|      DA|\n",
      "|                use refrigerator|      DA|\n",
      "|                         use fan|      DA|\n",
      "|                        use oven|      DA|\n",
      "|                       use stove|      DA|\n",
      "|     i would like to wash sheets|      DA|\n",
      "|i would like to watch television|      DA|\n",
      "+--------------------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDataset = spark.read \\\n",
    "      .option(\"header\", True) \\\n",
    "      .csv(\"text_test.csv\")\n",
    "testDataset.show(10, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "69940fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|category|count|\n",
      "+--------+-----+\n",
      "|      VC|   46|\n",
      "|      DA|   29|\n",
      "|      CC|   26|\n",
      "|      SD|   23|\n",
      "|      LR|   21|\n",
      "|      AR|   20|\n",
      "|      SN|   20|\n",
      "|     NAV|   18|\n",
      "|      NA|    1|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "trainDataset.groupBy(\"category\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b1ded33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|category|count|\n",
      "+--------+-----+\n",
      "|      VC|   46|\n",
      "|      DA|   29|\n",
      "|      CC|   26|\n",
      "|      SD|   23|\n",
      "|      LR|   21|\n",
      "|      AR|   20|\n",
      "|      SN|   20|\n",
      "|     NAV|   18|\n",
      "|      NA|    1|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDataset = spark.read \\\n",
    "      .option(\"header\", True) \\\n",
    "      .csv(\"text_test.csv\")\n",
    "testDataset.groupBy(\"category\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3e763ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_small_bert_L8_512 download started this may take some time.\n",
      "Approximate size to download 149.1 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 12:26:59.423623: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/2fc7d368c66b_classifier_dl10228576928999606746\n",
      "2023-03-02 12:26:59.482195: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-03-02 12:26:59.482222: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/2fc7d368c66b_classifier_dl10228576928999606746\n",
      "2023-03-02 12:26:59.774872: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-03-02 12:27:00.202004: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/2fc7d368c66b_classifier_dl10228576928999606746\n",
      "2023-03-02 12:27:00.312679: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 889067 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 500 - learning_rate: 0.005 - batch_size: 32 - training_examples: 204 - classes: 9\n",
      "Epoch 1/500 - 0.19s - loss: 16.323198 - acc: 0.10763889 - batches: 7\n",
      "Epoch 2/500 - 0.02s - loss: 14.5652075 - acc: 0.21354167 - batches: 7\n",
      "Epoch 3/500 - 0.02s - loss: 14.755829 - acc: 0.27083334 - batches: 7\n",
      "Epoch 4/500 - 0.02s - loss: 14.402666 - acc: 0.27083334 - batches: 7\n",
      "Epoch 5/500 - 0.02s - loss: 14.10333 - acc: 0.31770834 - batches: 7\n",
      "Epoch 6/500 - 0.02s - loss: 13.936717 - acc: 0.43923613 - batches: 7\n",
      "Epoch 7/500 - 0.02s - loss: 13.93435 - acc: 0.5503472 - batches: 7\n",
      "Epoch 8/500 - 0.02s - loss: 13.999413 - acc: 0.5763889 - batches: 7\n",
      "Epoch 9/500 - 0.02s - loss: 13.941489 - acc: 0.5868055 - batches: 7\n",
      "Epoch 10/500 - 0.02s - loss: 13.557045 - acc: 0.6614583 - batches: 7\n",
      "Epoch 11/500 - 0.02s - loss: 13.206701 - acc: 0.7743056 - batches: 7\n",
      "Epoch 12/500 - 0.02s - loss: 12.90479 - acc: 0.9114583 - batches: 7\n",
      "Epoch 13/500 - 0.02s - loss: 12.5584755 - acc: 0.9322917 - batches: 7\n",
      "Epoch 14/500 - 0.02s - loss: 12.218605 - acc: 0.9427083 - batches: 7\n",
      "Epoch 15/500 - 0.02s - loss: 11.965922 - acc: 0.9635417 - batches: 7\n",
      "Epoch 16/500 - 0.02s - loss: 11.8272085 - acc: 0.96875 - batches: 7\n",
      "Epoch 17/500 - 0.02s - loss: 11.751702 - acc: 0.98784727 - batches: 7\n",
      "Epoch 18/500 - 0.01s - loss: 11.705048 - acc: 0.9982639 - batches: 7\n",
      "Epoch 19/500 - 0.02s - loss: 11.673215 - acc: 1.0 - batches: 7\n",
      "Epoch 20/500 - 0.02s - loss: 11.649819 - acc: 1.0 - batches: 7\n",
      "Epoch 21/500 - 0.02s - loss: 11.631821 - acc: 1.0 - batches: 7\n",
      "Epoch 22/500 - 0.02s - loss: 11.617638 - acc: 1.0 - batches: 7\n",
      "Epoch 23/500 - 0.02s - loss: 11.606081 - acc: 1.0 - batches: 7\n",
      "Epoch 24/500 - 0.02s - loss: 11.596488 - acc: 1.0 - batches: 7\n",
      "Epoch 25/500 - 0.02s - loss: 11.588217 - acc: 1.0 - batches: 7\n",
      "Epoch 26/500 - 0.02s - loss: 11.581243 - acc: 1.0 - batches: 7\n",
      "Epoch 27/500 - 0.02s - loss: 11.575164 - acc: 1.0 - batches: 7\n",
      "Epoch 28/500 - 0.02s - loss: 11.569837 - acc: 1.0 - batches: 7\n",
      "Epoch 29/500 - 0.02s - loss: 11.565067 - acc: 1.0 - batches: 7\n",
      "Epoch 30/500 - 0.02s - loss: 11.560834 - acc: 1.0 - batches: 7\n",
      "Epoch 31/500 - 0.02s - loss: 11.557059 - acc: 1.0 - batches: 7\n",
      "Epoch 32/500 - 0.01s - loss: 11.553648 - acc: 1.0 - batches: 7\n",
      "Epoch 33/500 - 0.01s - loss: 11.550531 - acc: 1.0 - batches: 7\n",
      "Epoch 34/500 - 0.02s - loss: 11.547651 - acc: 1.0 - batches: 7\n",
      "Epoch 35/500 - 0.01s - loss: 11.5449915 - acc: 1.0 - batches: 7\n",
      "Epoch 36/500 - 0.02s - loss: 11.542511 - acc: 1.0 - batches: 7\n",
      "Epoch 37/500 - 0.02s - loss: 11.540146 - acc: 1.0 - batches: 7\n",
      "Epoch 38/500 - 0.02s - loss: 11.537846 - acc: 1.0 - batches: 7\n",
      "Epoch 39/500 - 0.01s - loss: 11.535619 - acc: 1.0 - batches: 7\n",
      "Epoch 40/500 - 0.01s - loss: 11.533453 - acc: 1.0 - batches: 7\n",
      "Epoch 41/500 - 0.02s - loss: 11.531313 - acc: 1.0 - batches: 7\n",
      "Epoch 42/500 - 0.01s - loss: 11.529196 - acc: 1.0 - batches: 7\n",
      "Epoch 43/500 - 0.01s - loss: 11.52714 - acc: 1.0 - batches: 7\n",
      "Epoch 44/500 - 0.01s - loss: 11.525087 - acc: 1.0 - batches: 7\n",
      "Epoch 45/500 - 0.02s - loss: 11.523006 - acc: 1.0 - batches: 7\n",
      "Epoch 46/500 - 0.02s - loss: 11.520878 - acc: 1.0 - batches: 7\n",
      "Epoch 47/500 - 0.01s - loss: 11.518659 - acc: 1.0 - batches: 7\n",
      "Epoch 48/500 - 0.02s - loss: 11.516321 - acc: 1.0 - batches: 7\n",
      "Epoch 49/500 - 0.01s - loss: 11.513868 - acc: 1.0 - batches: 7\n",
      "Epoch 50/500 - 0.02s - loss: 11.511305 - acc: 1.0 - batches: 7\n",
      "Epoch 51/500 - 0.02s - loss: 11.5085535 - acc: 1.0 - batches: 7\n",
      "Epoch 52/500 - 0.01s - loss: 11.505591 - acc: 1.0 - batches: 7\n",
      "Epoch 53/500 - 0.01s - loss: 11.50236 - acc: 1.0 - batches: 7\n",
      "Epoch 54/500 - 0.01s - loss: 11.498841 - acc: 1.0 - batches: 7\n",
      "Epoch 55/500 - 0.02s - loss: 11.494968 - acc: 1.0 - batches: 7\n",
      "Epoch 56/500 - 0.02s - loss: 11.490671 - acc: 1.0 - batches: 7\n",
      "Epoch 57/500 - 0.01s - loss: 11.485904 - acc: 1.0 - batches: 7\n",
      "Epoch 58/500 - 0.01s - loss: 11.480485 - acc: 1.0 - batches: 7\n",
      "Epoch 59/500 - 0.01s - loss: 11.474266 - acc: 1.0 - batches: 7\n",
      "Epoch 60/500 - 0.01s - loss: 11.467092 - acc: 1.0 - batches: 7\n",
      "Epoch 61/500 - 0.02s - loss: 11.45887 - acc: 1.0 - batches: 7\n",
      "Epoch 62/500 - 0.01s - loss: 11.449351 - acc: 1.0 - batches: 7\n",
      "Epoch 63/500 - 0.01s - loss: 11.438156 - acc: 1.0 - batches: 7\n",
      "Epoch 64/500 - 0.02s - loss: 11.424884 - acc: 1.0 - batches: 7\n",
      "Epoch 65/500 - 0.01s - loss: 11.409302 - acc: 1.0 - batches: 7\n",
      "Epoch 66/500 - 0.01s - loss: 11.390933 - acc: 1.0 - batches: 7\n",
      "Epoch 67/500 - 0.01s - loss: 11.369148 - acc: 1.0 - batches: 7\n",
      "Epoch 68/500 - 0.01s - loss: 11.343186 - acc: 1.0 - batches: 7\n",
      "Epoch 69/500 - 0.01s - loss: 11.312295 - acc: 1.0 - batches: 7\n",
      "Epoch 70/500 - 0.02s - loss: 11.276141 - acc: 1.0 - batches: 7\n",
      "Epoch 71/500 - 0.01s - loss: 11.2348175 - acc: 1.0 - batches: 7\n",
      "Epoch 72/500 - 0.01s - loss: 11.18927 - acc: 1.0 - batches: 7\n",
      "Epoch 73/500 - 0.01s - loss: 11.141026 - acc: 1.0 - batches: 7\n",
      "Epoch 74/500 - 0.01s - loss: 11.091404 - acc: 1.0 - batches: 7\n",
      "Epoch 75/500 - 0.01s - loss: 11.040972 - acc: 1.0 - batches: 7\n",
      "Epoch 76/500 - 0.01s - loss: 10.9920025 - acc: 1.0 - batches: 7\n",
      "Epoch 77/500 - 0.02s - loss: 10.946263 - acc: 1.0 - batches: 7\n",
      "Epoch 78/500 - 0.01s - loss: 10.905362 - acc: 1.0 - batches: 7\n",
      "Epoch 79/500 - 0.02s - loss: 10.870005 - acc: 1.0 - batches: 7\n",
      "Epoch 80/500 - 0.02s - loss: 10.840171 - acc: 1.0 - batches: 7\n",
      "Epoch 81/500 - 0.02s - loss: 10.815201 - acc: 1.0 - batches: 7\n",
      "Epoch 82/500 - 0.02s - loss: 10.794437 - acc: 1.0 - batches: 7\n",
      "Epoch 83/500 - 0.01s - loss: 10.776982 - acc: 1.0 - batches: 7\n",
      "Epoch 84/500 - 0.01s - loss: 10.762306 - acc: 1.0 - batches: 7\n",
      "Epoch 85/500 - 0.02s - loss: 10.749837 - acc: 1.0 - batches: 7\n",
      "Epoch 86/500 - 0.01s - loss: 10.739039 - acc: 1.0 - batches: 7\n",
      "Epoch 87/500 - 0.01s - loss: 10.729546 - acc: 1.0 - batches: 7\n",
      "Epoch 88/500 - 0.02s - loss: 10.721222 - acc: 1.0 - batches: 7\n",
      "Epoch 89/500 - 0.01s - loss: 10.713835 - acc: 1.0 - batches: 7\n",
      "Epoch 90/500 - 0.02s - loss: 10.707155 - acc: 1.0 - batches: 7\n",
      "Epoch 91/500 - 0.01s - loss: 10.7011 - acc: 1.0 - batches: 7\n",
      "Epoch 92/500 - 0.01s - loss: 10.695582 - acc: 1.0 - batches: 7\n",
      "Epoch 93/500 - 0.02s - loss: 10.69056 - acc: 1.0 - batches: 7\n",
      "Epoch 94/500 - 0.01s - loss: 10.685939 - acc: 1.0 - batches: 7\n",
      "Epoch 95/500 - 0.01s - loss: 10.681642 - acc: 1.0 - batches: 7\n",
      "Epoch 96/500 - 0.02s - loss: 10.677583 - acc: 1.0 - batches: 7\n",
      "Epoch 97/500 - 0.01s - loss: 10.673759 - acc: 1.0 - batches: 7\n",
      "Epoch 98/500 - 0.02s - loss: 10.670187 - acc: 1.0 - batches: 7\n",
      "Epoch 99/500 - 0.02s - loss: 10.666854 - acc: 1.0 - batches: 7\n",
      "Epoch 100/500 - 0.01s - loss: 10.663718 - acc: 1.0 - batches: 7\n",
      "Epoch 101/500 - 0.01s - loss: 10.660762 - acc: 1.0 - batches: 7\n",
      "Epoch 102/500 - 0.02s - loss: 10.657967 - acc: 1.0 - batches: 7\n",
      "Epoch 103/500 - 0.01s - loss: 10.655336 - acc: 1.0 - batches: 7\n",
      "Epoch 104/500 - 0.01s - loss: 10.652869 - acc: 1.0 - batches: 7\n",
      "Epoch 105/500 - 0.02s - loss: 10.650531 - acc: 1.0 - batches: 7\n",
      "Epoch 106/500 - 0.02s - loss: 10.648295 - acc: 1.0 - batches: 7\n",
      "Epoch 107/500 - 0.02s - loss: 10.646166 - acc: 1.0 - batches: 7\n",
      "Epoch 108/500 - 0.01s - loss: 10.6441345 - acc: 1.0 - batches: 7\n",
      "Epoch 109/500 - 0.01s - loss: 10.642202 - acc: 1.0 - batches: 7\n",
      "Epoch 110/500 - 0.01s - loss: 10.640356 - acc: 1.0 - batches: 7\n",
      "Epoch 111/500 - 0.01s - loss: 10.638576 - acc: 1.0 - batches: 7\n",
      "Epoch 112/500 - 0.02s - loss: 10.636864 - acc: 1.0 - batches: 7\n",
      "Epoch 113/500 - 0.01s - loss: 10.635242 - acc: 1.0 - batches: 7\n",
      "Epoch 114/500 - 0.02s - loss: 10.63369 - acc: 1.0 - batches: 7\n",
      "Epoch 115/500 - 0.02s - loss: 10.632202 - acc: 1.0 - batches: 7\n",
      "Epoch 116/500 - 0.02s - loss: 10.630795 - acc: 1.0 - batches: 7\n",
      "Epoch 117/500 - 0.02s - loss: 10.629465 - acc: 1.0 - batches: 7\n",
      "Epoch 118/500 - 0.01s - loss: 10.628181 - acc: 1.0 - batches: 7\n",
      "Epoch 119/500 - 0.01s - loss: 10.626941 - acc: 1.0 - batches: 7\n",
      "Epoch 120/500 - 0.01s - loss: 10.625759 - acc: 1.0 - batches: 7\n",
      "Epoch 121/500 - 0.02s - loss: 10.624607 - acc: 1.0 - batches: 7\n",
      "Epoch 122/500 - 0.01s - loss: 10.623488 - acc: 1.0 - batches: 7\n",
      "Epoch 123/500 - 0.01s - loss: 10.622406 - acc: 1.0 - batches: 7\n",
      "Epoch 124/500 - 0.01s - loss: 10.621362 - acc: 1.0 - batches: 7\n",
      "Epoch 125/500 - 0.02s - loss: 10.620358 - acc: 1.0 - batches: 7\n",
      "Epoch 126/500 - 0.02s - loss: 10.619388 - acc: 1.0 - batches: 7\n",
      "Epoch 127/500 - 0.02s - loss: 10.618449 - acc: 1.0 - batches: 7\n",
      "Epoch 128/500 - 0.02s - loss: 10.617545 - acc: 1.0 - batches: 7\n",
      "Epoch 129/500 - 0.01s - loss: 10.61667 - acc: 1.0 - batches: 7\n",
      "Epoch 130/500 - 0.01s - loss: 10.615818 - acc: 1.0 - batches: 7\n",
      "Epoch 131/500 - 0.01s - loss: 10.615002 - acc: 1.0 - batches: 7\n",
      "Epoch 132/500 - 0.01s - loss: 10.614217 - acc: 1.0 - batches: 7\n",
      "Epoch 133/500 - 0.01s - loss: 10.613455 - acc: 1.0 - batches: 7\n",
      "Epoch 134/500 - 0.02s - loss: 10.612719 - acc: 1.0 - batches: 7\n",
      "Epoch 135/500 - 0.01s - loss: 10.612003 - acc: 1.0 - batches: 7\n",
      "Epoch 136/500 - 0.02s - loss: 10.611313 - acc: 1.0 - batches: 7\n",
      "Epoch 137/500 - 0.02s - loss: 10.610638 - acc: 1.0 - batches: 7\n",
      "Epoch 138/500 - 0.01s - loss: 10.60998 - acc: 1.0 - batches: 7\n",
      "Epoch 139/500 - 0.01s - loss: 10.609345 - acc: 1.0 - batches: 7\n",
      "Epoch 140/500 - 0.02s - loss: 10.608732 - acc: 1.0 - batches: 7\n",
      "Epoch 141/500 - 0.02s - loss: 10.608137 - acc: 1.0 - batches: 7\n",
      "Epoch 142/500 - 0.02s - loss: 10.607563 - acc: 1.0 - batches: 7\n",
      "Epoch 143/500 - 0.01s - loss: 10.607001 - acc: 1.0 - batches: 7\n",
      "Epoch 144/500 - 0.02s - loss: 10.606457 - acc: 1.0 - batches: 7\n",
      "Epoch 145/500 - 0.01s - loss: 10.605928 - acc: 1.0 - batches: 7\n",
      "Epoch 146/500 - 0.02s - loss: 10.605417 - acc: 1.0 - batches: 7\n",
      "Epoch 147/500 - 0.02s - loss: 10.6049185 - acc: 1.0 - batches: 7\n",
      "Epoch 148/500 - 0.02s - loss: 10.604427 - acc: 1.0 - batches: 7\n",
      "Epoch 149/500 - 0.02s - loss: 10.6039505 - acc: 1.0 - batches: 7\n",
      "Epoch 150/500 - 0.02s - loss: 10.603484 - acc: 1.0 - batches: 7\n",
      "Epoch 151/500 - 0.02s - loss: 10.603035 - acc: 1.0 - batches: 7\n",
      "Epoch 152/500 - 0.01s - loss: 10.602605 - acc: 1.0 - batches: 7\n",
      "Epoch 153/500 - 0.02s - loss: 10.602189 - acc: 1.0 - batches: 7\n",
      "Epoch 154/500 - 0.02s - loss: 10.601776 - acc: 1.0 - batches: 7\n",
      "Epoch 155/500 - 0.02s - loss: 10.601364 - acc: 1.0 - batches: 7\n",
      "Epoch 156/500 - 0.01s - loss: 10.600966 - acc: 1.0 - batches: 7\n",
      "Epoch 157/500 - 0.01s - loss: 10.600581 - acc: 1.0 - batches: 7\n",
      "Epoch 158/500 - 0.01s - loss: 10.6002035 - acc: 1.0 - batches: 7\n",
      "Epoch 159/500 - 0.01s - loss: 10.599836 - acc: 1.0 - batches: 7\n",
      "Epoch 160/500 - 0.01s - loss: 10.599481 - acc: 1.0 - batches: 7\n",
      "Epoch 161/500 - 0.02s - loss: 10.599129 - acc: 1.0 - batches: 7\n",
      "Epoch 162/500 - 0.01s - loss: 10.598785 - acc: 1.0 - batches: 7\n",
      "Epoch 163/500 - 0.02s - loss: 10.598453 - acc: 1.0 - batches: 7\n",
      "Epoch 164/500 - 0.01s - loss: 10.598125 - acc: 1.0 - batches: 7\n",
      "Epoch 165/500 - 0.01s - loss: 10.597802 - acc: 1.0 - batches: 7\n",
      "Epoch 166/500 - 0.02s - loss: 10.5974865 - acc: 1.0 - batches: 7\n",
      "Epoch 167/500 - 0.01s - loss: 10.597178 - acc: 1.0 - batches: 7\n",
      "Epoch 168/500 - 0.02s - loss: 10.596872 - acc: 1.0 - batches: 7\n",
      "Epoch 169/500 - 0.01s - loss: 10.596571 - acc: 1.0 - batches: 7\n",
      "Epoch 170/500 - 0.02s - loss: 10.596274 - acc: 1.0 - batches: 7\n",
      "Epoch 171/500 - 0.01s - loss: 10.595988 - acc: 1.0 - batches: 7\n",
      "Epoch 172/500 - 0.01s - loss: 10.595709 - acc: 1.0 - batches: 7\n",
      "Epoch 173/500 - 0.01s - loss: 10.595431 - acc: 1.0 - batches: 7\n",
      "Epoch 174/500 - 0.01s - loss: 10.595149 - acc: 1.0 - batches: 7\n",
      "Epoch 175/500 - 0.01s - loss: 10.594872 - acc: 1.0 - batches: 7\n",
      "Epoch 176/500 - 0.01s - loss: 10.594606 - acc: 1.0 - batches: 7\n",
      "Epoch 177/500 - 0.01s - loss: 10.594345 - acc: 1.0 - batches: 7\n",
      "Epoch 178/500 - 0.02s - loss: 10.594087 - acc: 1.0 - batches: 7\n",
      "Epoch 179/500 - 0.01s - loss: 10.593836 - acc: 1.0 - batches: 7\n",
      "Epoch 180/500 - 0.01s - loss: 10.593592 - acc: 1.0 - batches: 7\n",
      "Epoch 181/500 - 0.01s - loss: 10.593354 - acc: 1.0 - batches: 7\n",
      "Epoch 182/500 - 0.01s - loss: 10.593125 - acc: 1.0 - batches: 7\n",
      "Epoch 183/500 - 0.01s - loss: 10.592895 - acc: 1.0 - batches: 7\n",
      "Epoch 184/500 - 0.02s - loss: 10.592669 - acc: 1.0 - batches: 7\n",
      "Epoch 185/500 - 0.01s - loss: 10.592451 - acc: 1.0 - batches: 7\n",
      "Epoch 186/500 - 0.01s - loss: 10.592239 - acc: 1.0 - batches: 7\n",
      "Epoch 187/500 - 0.01s - loss: 10.592026 - acc: 1.0 - batches: 7\n",
      "Epoch 188/500 - 0.01s - loss: 10.591813 - acc: 1.0 - batches: 7\n",
      "Epoch 189/500 - 0.01s - loss: 10.591604 - acc: 1.0 - batches: 7\n",
      "Epoch 190/500 - 0.01s - loss: 10.591401 - acc: 1.0 - batches: 7\n",
      "Epoch 191/500 - 0.01s - loss: 10.591201 - acc: 1.0 - batches: 7\n",
      "Epoch 192/500 - 0.01s - loss: 10.591003 - acc: 1.0 - batches: 7\n",
      "Epoch 193/500 - 0.01s - loss: 10.590807 - acc: 1.0 - batches: 7\n",
      "Epoch 194/500 - 0.01s - loss: 10.590614 - acc: 1.0 - batches: 7\n",
      "Epoch 195/500 - 0.02s - loss: 10.590425 - acc: 1.0 - batches: 7\n",
      "Epoch 196/500 - 0.01s - loss: 10.5902405 - acc: 1.0 - batches: 7\n",
      "Epoch 197/500 - 0.01s - loss: 10.5900545 - acc: 1.0 - batches: 7\n",
      "Epoch 198/500 - 0.01s - loss: 10.5898695 - acc: 1.0 - batches: 7\n",
      "Epoch 199/500 - 0.01s - loss: 10.589695 - acc: 1.0 - batches: 7\n",
      "Epoch 200/500 - 0.01s - loss: 10.589523 - acc: 1.0 - batches: 7\n",
      "Epoch 201/500 - 0.01s - loss: 10.589353 - acc: 1.0 - batches: 7\n",
      "Epoch 202/500 - 0.01s - loss: 10.589184 - acc: 1.0 - batches: 7\n",
      "Epoch 203/500 - 0.01s - loss: 10.589014 - acc: 1.0 - batches: 7\n",
      "Epoch 204/500 - 0.02s - loss: 10.588851 - acc: 1.0 - batches: 7\n",
      "Epoch 205/500 - 0.01s - loss: 10.588691 - acc: 1.0 - batches: 7\n",
      "Epoch 206/500 - 0.01s - loss: 10.58853 - acc: 1.0 - batches: 7\n",
      "Epoch 207/500 - 0.01s - loss: 10.588372 - acc: 1.0 - batches: 7\n",
      "Epoch 208/500 - 0.01s - loss: 10.58822 - acc: 1.0 - batches: 7\n",
      "Epoch 209/500 - 0.01s - loss: 10.588068 - acc: 1.0 - batches: 7\n",
      "Epoch 210/500 - 0.01s - loss: 10.587918 - acc: 1.0 - batches: 7\n",
      "Epoch 211/500 - 0.01s - loss: 10.58777 - acc: 1.0 - batches: 7\n",
      "Epoch 212/500 - 0.01s - loss: 10.587622 - acc: 1.0 - batches: 7\n",
      "Epoch 213/500 - 0.02s - loss: 10.587478 - acc: 1.0 - batches: 7\n",
      "Epoch 214/500 - 0.02s - loss: 10.587336 - acc: 1.0 - batches: 7\n",
      "Epoch 215/500 - 0.02s - loss: 10.587193 - acc: 1.0 - batches: 7\n",
      "Epoch 216/500 - 0.02s - loss: 10.587053 - acc: 1.0 - batches: 7\n",
      "Epoch 217/500 - 0.02s - loss: 10.586916 - acc: 1.0 - batches: 7\n",
      "Epoch 218/500 - 0.02s - loss: 10.586779 - acc: 1.0 - batches: 7\n",
      "Epoch 219/500 - 0.02s - loss: 10.586645 - acc: 1.0 - batches: 7\n",
      "Epoch 220/500 - 0.02s - loss: 10.586515 - acc: 1.0 - batches: 7\n",
      "Epoch 221/500 - 0.02s - loss: 10.586388 - acc: 1.0 - batches: 7\n",
      "Epoch 222/500 - 0.01s - loss: 10.586259 - acc: 1.0 - batches: 7\n",
      "Epoch 223/500 - 0.01s - loss: 10.586134 - acc: 1.0 - batches: 7\n",
      "Epoch 224/500 - 0.01s - loss: 10.586009 - acc: 1.0 - batches: 7\n",
      "Epoch 225/500 - 0.01s - loss: 10.585888 - acc: 1.0 - batches: 7\n",
      "Epoch 226/500 - 0.02s - loss: 10.585767 - acc: 1.0 - batches: 7\n",
      "Epoch 227/500 - 0.02s - loss: 10.5856495 - acc: 1.0 - batches: 7\n",
      "Epoch 228/500 - 0.02s - loss: 10.585531 - acc: 1.0 - batches: 7\n",
      "Epoch 229/500 - 0.02s - loss: 10.585413 - acc: 1.0 - batches: 7\n",
      "Epoch 230/500 - 0.02s - loss: 10.585297 - acc: 1.0 - batches: 7\n",
      "Epoch 231/500 - 0.02s - loss: 10.585182 - acc: 1.0 - batches: 7\n",
      "Epoch 232/500 - 0.02s - loss: 10.585068 - acc: 1.0 - batches: 7\n",
      "Epoch 233/500 - 0.02s - loss: 10.584955 - acc: 1.0 - batches: 7\n",
      "Epoch 234/500 - 0.01s - loss: 10.584844 - acc: 1.0 - batches: 7\n",
      "Epoch 235/500 - 0.02s - loss: 10.584733 - acc: 1.0 - batches: 7\n",
      "Epoch 236/500 - 0.02s - loss: 10.584624 - acc: 1.0 - batches: 7\n",
      "Epoch 237/500 - 0.02s - loss: 10.584519 - acc: 1.0 - batches: 7\n",
      "Epoch 238/500 - 0.02s - loss: 10.584411 - acc: 1.0 - batches: 7\n",
      "Epoch 239/500 - 0.02s - loss: 10.584302 - acc: 1.0 - batches: 7\n",
      "Epoch 240/500 - 0.01s - loss: 10.584197 - acc: 1.0 - batches: 7\n",
      "Epoch 241/500 - 0.01s - loss: 10.584093 - acc: 1.0 - batches: 7\n",
      "Epoch 242/500 - 0.01s - loss: 10.583992 - acc: 1.0 - batches: 7\n",
      "Epoch 243/500 - 0.01s - loss: 10.583893 - acc: 1.0 - batches: 7\n",
      "Epoch 244/500 - 0.01s - loss: 10.583793 - acc: 1.0 - batches: 7\n",
      "Epoch 245/500 - 0.01s - loss: 10.583695 - acc: 1.0 - batches: 7\n",
      "Epoch 246/500 - 0.01s - loss: 10.583599 - acc: 1.0 - batches: 7\n",
      "Epoch 247/500 - 0.02s - loss: 10.583503 - acc: 1.0 - batches: 7\n",
      "Epoch 248/500 - 0.01s - loss: 10.583409 - acc: 1.0 - batches: 7\n",
      "Epoch 249/500 - 0.02s - loss: 10.583316 - acc: 1.0 - batches: 7\n",
      "Epoch 250/500 - 0.01s - loss: 10.583225 - acc: 1.0 - batches: 7\n",
      "Epoch 251/500 - 0.02s - loss: 10.583136 - acc: 1.0 - batches: 7\n",
      "Epoch 252/500 - 0.01s - loss: 10.583048 - acc: 1.0 - batches: 7\n",
      "Epoch 253/500 - 0.02s - loss: 10.582959 - acc: 1.0 - batches: 7\n",
      "Epoch 254/500 - 0.02s - loss: 10.582872 - acc: 1.0 - batches: 7\n",
      "Epoch 255/500 - 0.02s - loss: 10.5827875 - acc: 1.0 - batches: 7\n",
      "Epoch 256/500 - 0.02s - loss: 10.582704 - acc: 1.0 - batches: 7\n",
      "Epoch 257/500 - 0.02s - loss: 10.582618 - acc: 1.0 - batches: 7\n",
      "Epoch 258/500 - 0.02s - loss: 10.582537 - acc: 1.0 - batches: 7\n",
      "Epoch 259/500 - 0.01s - loss: 10.582457 - acc: 1.0 - batches: 7\n",
      "Epoch 260/500 - 0.02s - loss: 10.582377 - acc: 1.0 - batches: 7\n",
      "Epoch 261/500 - 0.02s - loss: 10.582298 - acc: 1.0 - batches: 7\n",
      "Epoch 262/500 - 0.02s - loss: 10.58222 - acc: 1.0 - batches: 7\n",
      "Epoch 263/500 - 0.01s - loss: 10.582143 - acc: 1.0 - batches: 7\n",
      "Epoch 264/500 - 0.02s - loss: 10.582067 - acc: 1.0 - batches: 7\n",
      "Epoch 265/500 - 0.01s - loss: 10.58199 - acc: 1.0 - batches: 7\n",
      "Epoch 266/500 - 0.01s - loss: 10.581914 - acc: 1.0 - batches: 7\n",
      "Epoch 267/500 - 0.01s - loss: 10.58184 - acc: 1.0 - batches: 7\n",
      "Epoch 268/500 - 0.01s - loss: 10.581769 - acc: 1.0 - batches: 7\n",
      "Epoch 269/500 - 0.02s - loss: 10.581696 - acc: 1.0 - batches: 7\n",
      "Epoch 270/500 - 0.01s - loss: 10.581624 - acc: 1.0 - batches: 7\n",
      "Epoch 271/500 - 0.01s - loss: 10.581551 - acc: 1.0 - batches: 7\n",
      "Epoch 272/500 - 0.01s - loss: 10.581479 - acc: 1.0 - batches: 7\n",
      "Epoch 273/500 - 0.02s - loss: 10.581409 - acc: 1.0 - batches: 7\n",
      "Epoch 274/500 - 0.01s - loss: 10.58134 - acc: 1.0 - batches: 7\n",
      "Epoch 275/500 - 0.01s - loss: 10.58127 - acc: 1.0 - batches: 7\n",
      "Epoch 276/500 - 0.01s - loss: 10.581202 - acc: 1.0 - batches: 7\n",
      "Epoch 277/500 - 0.01s - loss: 10.581134 - acc: 1.0 - batches: 7\n",
      "Epoch 278/500 - 0.01s - loss: 10.581065 - acc: 1.0 - batches: 7\n",
      "Epoch 279/500 - 0.02s - loss: 10.580997 - acc: 1.0 - batches: 7\n",
      "Epoch 280/500 - 0.02s - loss: 10.580933 - acc: 1.0 - batches: 7\n",
      "Epoch 281/500 - 0.01s - loss: 10.580866 - acc: 1.0 - batches: 7\n",
      "Epoch 282/500 - 0.01s - loss: 10.580799 - acc: 1.0 - batches: 7\n",
      "Epoch 283/500 - 0.01s - loss: 10.580734 - acc: 1.0 - batches: 7\n",
      "Epoch 284/500 - 0.01s - loss: 10.580671 - acc: 1.0 - batches: 7\n",
      "Epoch 285/500 - 0.02s - loss: 10.580606 - acc: 1.0 - batches: 7\n",
      "Epoch 286/500 - 0.01s - loss: 10.580542 - acc: 1.0 - batches: 7\n",
      "Epoch 287/500 - 0.01s - loss: 10.58048 - acc: 1.0 - batches: 7\n",
      "Epoch 288/500 - 0.02s - loss: 10.580419 - acc: 1.0 - batches: 7\n",
      "Epoch 289/500 - 0.02s - loss: 10.580355 - acc: 1.0 - batches: 7\n",
      "Epoch 290/500 - 0.01s - loss: 10.580295 - acc: 1.0 - batches: 7\n",
      "Epoch 291/500 - 0.02s - loss: 10.580233 - acc: 1.0 - batches: 7\n",
      "Epoch 292/500 - 0.02s - loss: 10.5801735 - acc: 1.0 - batches: 7\n",
      "Epoch 293/500 - 0.01s - loss: 10.580113 - acc: 1.0 - batches: 7\n",
      "Epoch 294/500 - 0.02s - loss: 10.580053 - acc: 1.0 - batches: 7\n",
      "Epoch 295/500 - 0.01s - loss: 10.579996 - acc: 1.0 - batches: 7\n",
      "Epoch 296/500 - 0.02s - loss: 10.579937 - acc: 1.0 - batches: 7\n",
      "Epoch 297/500 - 0.02s - loss: 10.579879 - acc: 1.0 - batches: 7\n",
      "Epoch 298/500 - 0.02s - loss: 10.579822 - acc: 1.0 - batches: 7\n",
      "Epoch 299/500 - 0.02s - loss: 10.579765 - acc: 1.0 - batches: 7\n",
      "Epoch 300/500 - 0.02s - loss: 10.579709 - acc: 1.0 - batches: 7\n",
      "Epoch 301/500 - 0.02s - loss: 10.579652 - acc: 1.0 - batches: 7\n",
      "Epoch 302/500 - 0.02s - loss: 10.5795965 - acc: 1.0 - batches: 7\n",
      "Epoch 303/500 - 0.02s - loss: 10.579542 - acc: 1.0 - batches: 7\n",
      "Epoch 304/500 - 0.01s - loss: 10.579487 - acc: 1.0 - batches: 7\n",
      "Epoch 305/500 - 0.02s - loss: 10.579432 - acc: 1.0 - batches: 7\n",
      "Epoch 306/500 - 0.02s - loss: 10.579379 - acc: 1.0 - batches: 7\n",
      "Epoch 307/500 - 0.02s - loss: 10.579327 - acc: 1.0 - batches: 7\n",
      "Epoch 308/500 - 0.01s - loss: 10.579273 - acc: 1.0 - batches: 7\n",
      "Epoch 309/500 - 0.02s - loss: 10.579222 - acc: 1.0 - batches: 7\n",
      "Epoch 310/500 - 0.02s - loss: 10.57917 - acc: 1.0 - batches: 7\n",
      "Epoch 311/500 - 0.02s - loss: 10.57912 - acc: 1.0 - batches: 7\n",
      "Epoch 312/500 - 0.02s - loss: 10.579069 - acc: 1.0 - batches: 7\n",
      "Epoch 313/500 - 0.02s - loss: 10.579019 - acc: 1.0 - batches: 7\n",
      "Epoch 314/500 - 0.02s - loss: 10.578968 - acc: 1.0 - batches: 7\n",
      "Epoch 315/500 - 0.02s - loss: 10.578918 - acc: 1.0 - batches: 7\n",
      "Epoch 316/500 - 0.02s - loss: 10.57887 - acc: 1.0 - batches: 7\n",
      "Epoch 317/500 - 0.02s - loss: 10.578821 - acc: 1.0 - batches: 7\n",
      "Epoch 318/500 - 0.02s - loss: 10.578772 - acc: 1.0 - batches: 7\n",
      "Epoch 319/500 - 0.02s - loss: 10.578725 - acc: 1.0 - batches: 7\n",
      "Epoch 320/500 - 0.02s - loss: 10.578678 - acc: 1.0 - batches: 7\n",
      "Epoch 321/500 - 0.02s - loss: 10.578631 - acc: 1.0 - batches: 7\n",
      "Epoch 322/500 - 0.02s - loss: 10.578585 - acc: 1.0 - batches: 7\n",
      "Epoch 323/500 - 0.02s - loss: 10.578537 - acc: 1.0 - batches: 7\n",
      "Epoch 324/500 - 0.02s - loss: 10.57849 - acc: 1.0 - batches: 7\n",
      "Epoch 325/500 - 0.02s - loss: 10.5784445 - acc: 1.0 - batches: 7\n",
      "Epoch 326/500 - 0.01s - loss: 10.5784 - acc: 1.0 - batches: 7\n",
      "Epoch 327/500 - 0.02s - loss: 10.578354 - acc: 1.0 - batches: 7\n",
      "Epoch 328/500 - 0.02s - loss: 10.57831 - acc: 1.0 - batches: 7\n",
      "Epoch 329/500 - 0.02s - loss: 10.578265 - acc: 1.0 - batches: 7\n",
      "Epoch 330/500 - 0.01s - loss: 10.578221 - acc: 1.0 - batches: 7\n",
      "Epoch 331/500 - 0.01s - loss: 10.5781765 - acc: 1.0 - batches: 7\n",
      "Epoch 332/500 - 0.01s - loss: 10.578133 - acc: 1.0 - batches: 7\n",
      "Epoch 333/500 - 0.01s - loss: 10.578089 - acc: 1.0 - batches: 7\n",
      "Epoch 334/500 - 0.01s - loss: 10.578046 - acc: 1.0 - batches: 7\n",
      "Epoch 335/500 - 0.01s - loss: 10.578003 - acc: 1.0 - batches: 7\n",
      "Epoch 336/500 - 0.01s - loss: 10.577961 - acc: 1.0 - batches: 7\n",
      "Epoch 337/500 - 0.01s - loss: 10.577919 - acc: 1.0 - batches: 7\n",
      "Epoch 338/500 - 0.02s - loss: 10.577877 - acc: 1.0 - batches: 7\n",
      "Epoch 339/500 - 0.02s - loss: 10.577836 - acc: 1.0 - batches: 7\n",
      "Epoch 340/500 - 0.02s - loss: 10.577796 - acc: 1.0 - batches: 7\n",
      "Epoch 341/500 - 0.02s - loss: 10.577756 - acc: 1.0 - batches: 7\n",
      "Epoch 342/500 - 0.01s - loss: 10.577716 - acc: 1.0 - batches: 7\n",
      "Epoch 343/500 - 0.01s - loss: 10.577676 - acc: 1.0 - batches: 7\n",
      "Epoch 344/500 - 0.01s - loss: 10.577638 - acc: 1.0 - batches: 7\n",
      "Epoch 345/500 - 0.02s - loss: 10.577599 - acc: 1.0 - batches: 7\n",
      "Epoch 346/500 - 0.02s - loss: 10.57756 - acc: 1.0 - batches: 7\n",
      "Epoch 347/500 - 0.02s - loss: 10.577521 - acc: 1.0 - batches: 7\n",
      "Epoch 348/500 - 0.02s - loss: 10.577483 - acc: 1.0 - batches: 7\n",
      "Epoch 349/500 - 0.01s - loss: 10.577445 - acc: 1.0 - batches: 7\n",
      "Epoch 350/500 - 0.01s - loss: 10.577406 - acc: 1.0 - batches: 7\n",
      "Epoch 351/500 - 0.01s - loss: 10.57737 - acc: 1.0 - batches: 7\n",
      "Epoch 352/500 - 0.01s - loss: 10.577332 - acc: 1.0 - batches: 7\n",
      "Epoch 353/500 - 0.01s - loss: 10.577294 - acc: 1.0 - batches: 7\n",
      "Epoch 354/500 - 0.02s - loss: 10.577257 - acc: 1.0 - batches: 7\n",
      "Epoch 355/500 - 0.02s - loss: 10.577219 - acc: 1.0 - batches: 7\n",
      "Epoch 356/500 - 0.02s - loss: 10.577184 - acc: 1.0 - batches: 7\n",
      "Epoch 357/500 - 0.01s - loss: 10.5771475 - acc: 1.0 - batches: 7\n",
      "Epoch 358/500 - 0.01s - loss: 10.57711 - acc: 1.0 - batches: 7\n",
      "Epoch 359/500 - 0.02s - loss: 10.577076 - acc: 1.0 - batches: 7\n",
      "Epoch 360/500 - 0.02s - loss: 10.577041 - acc: 1.0 - batches: 7\n",
      "Epoch 361/500 - 0.02s - loss: 10.577006 - acc: 1.0 - batches: 7\n",
      "Epoch 362/500 - 0.02s - loss: 10.576972 - acc: 1.0 - batches: 7\n",
      "Epoch 363/500 - 0.01s - loss: 10.576936 - acc: 1.0 - batches: 7\n",
      "Epoch 364/500 - 0.01s - loss: 10.576902 - acc: 1.0 - batches: 7\n",
      "Epoch 365/500 - 0.02s - loss: 10.576868 - acc: 1.0 - batches: 7\n",
      "Epoch 366/500 - 0.01s - loss: 10.576835 - acc: 1.0 - batches: 7\n",
      "Epoch 367/500 - 0.02s - loss: 10.576801 - acc: 1.0 - batches: 7\n",
      "Epoch 368/500 - 0.01s - loss: 10.576767 - acc: 1.0 - batches: 7\n",
      "Epoch 369/500 - 0.01s - loss: 10.576735 - acc: 1.0 - batches: 7\n",
      "Epoch 370/500 - 0.02s - loss: 10.576702 - acc: 1.0 - batches: 7\n",
      "Epoch 371/500 - 0.01s - loss: 10.576671 - acc: 1.0 - batches: 7\n",
      "Epoch 372/500 - 0.01s - loss: 10.576638 - acc: 1.0 - batches: 7\n",
      "Epoch 373/500 - 0.02s - loss: 10.576606 - acc: 1.0 - batches: 7\n",
      "Epoch 374/500 - 0.01s - loss: 10.576574 - acc: 1.0 - batches: 7\n",
      "Epoch 375/500 - 0.01s - loss: 10.576544 - acc: 1.0 - batches: 7\n",
      "Epoch 376/500 - 0.01s - loss: 10.576511 - acc: 1.0 - batches: 7\n",
      "Epoch 377/500 - 0.01s - loss: 10.576483 - acc: 1.0 - batches: 7\n",
      "Epoch 378/500 - 0.02s - loss: 10.576453 - acc: 1.0 - batches: 7\n",
      "Epoch 379/500 - 0.01s - loss: 10.576423 - acc: 1.0 - batches: 7\n",
      "Epoch 380/500 - 0.01s - loss: 10.576394 - acc: 1.0 - batches: 7\n",
      "Epoch 381/500 - 0.01s - loss: 10.5763645 - acc: 1.0 - batches: 7\n",
      "Epoch 382/500 - 0.01s - loss: 10.576336 - acc: 1.0 - batches: 7\n",
      "Epoch 383/500 - 0.02s - loss: 10.576305 - acc: 1.0 - batches: 7\n",
      "Epoch 384/500 - 0.02s - loss: 10.576278 - acc: 1.0 - batches: 7\n",
      "Epoch 385/500 - 0.01s - loss: 10.576249 - acc: 1.0 - batches: 7\n",
      "Epoch 386/500 - 0.01s - loss: 10.576222 - acc: 1.0 - batches: 7\n",
      "Epoch 387/500 - 0.02s - loss: 10.576194 - acc: 1.0 - batches: 7\n",
      "Epoch 388/500 - 0.01s - loss: 10.576164 - acc: 1.0 - batches: 7\n",
      "Epoch 389/500 - 0.02s - loss: 10.576138 - acc: 1.0 - batches: 7\n",
      "Epoch 390/500 - 0.02s - loss: 10.576111 - acc: 1.0 - batches: 7\n",
      "Epoch 391/500 - 0.01s - loss: 10.576084 - acc: 1.0 - batches: 7\n",
      "Epoch 392/500 - 0.01s - loss: 10.576057 - acc: 1.0 - batches: 7\n",
      "Epoch 393/500 - 0.02s - loss: 10.576031 - acc: 1.0 - batches: 7\n",
      "Epoch 394/500 - 0.01s - loss: 10.576004 - acc: 1.0 - batches: 7\n",
      "Epoch 395/500 - 0.02s - loss: 10.57598 - acc: 1.0 - batches: 7\n",
      "Epoch 396/500 - 0.02s - loss: 10.575955 - acc: 1.0 - batches: 7\n",
      "Epoch 397/500 - 0.02s - loss: 10.575928 - acc: 1.0 - batches: 7\n",
      "Epoch 398/500 - 0.01s - loss: 10.575903 - acc: 1.0 - batches: 7\n",
      "Epoch 399/500 - 0.02s - loss: 10.575878 - acc: 1.0 - batches: 7\n",
      "Epoch 400/500 - 0.01s - loss: 10.575854 - acc: 1.0 - batches: 7\n",
      "Epoch 401/500 - 0.02s - loss: 10.575831 - acc: 1.0 - batches: 7\n",
      "Epoch 402/500 - 0.02s - loss: 10.575806 - acc: 1.0 - batches: 7\n",
      "Epoch 403/500 - 0.01s - loss: 10.575782 - acc: 1.0 - batches: 7\n",
      "Epoch 404/500 - 0.02s - loss: 10.575758 - acc: 1.0 - batches: 7\n",
      "Epoch 405/500 - 0.01s - loss: 10.575733 - acc: 1.0 - batches: 7\n",
      "Epoch 406/500 - 0.01s - loss: 10.575709 - acc: 1.0 - batches: 7\n",
      "Epoch 407/500 - 0.02s - loss: 10.5756855 - acc: 1.0 - batches: 7\n",
      "Epoch 408/500 - 0.01s - loss: 10.575663 - acc: 1.0 - batches: 7\n",
      "Epoch 409/500 - 0.02s - loss: 10.57564 - acc: 1.0 - batches: 7\n",
      "Epoch 410/500 - 0.02s - loss: 10.575617 - acc: 1.0 - batches: 7\n",
      "Epoch 411/500 - 0.02s - loss: 10.575594 - acc: 1.0 - batches: 7\n",
      "Epoch 412/500 - 0.01s - loss: 10.575571 - acc: 1.0 - batches: 7\n",
      "Epoch 413/500 - 0.01s - loss: 10.575548 - acc: 1.0 - batches: 7\n",
      "Epoch 414/500 - 0.01s - loss: 10.575526 - acc: 1.0 - batches: 7\n",
      "Epoch 415/500 - 0.01s - loss: 10.575503 - acc: 1.0 - batches: 7\n",
      "Epoch 416/500 - 0.02s - loss: 10.575482 - acc: 1.0 - batches: 7\n",
      "Epoch 417/500 - 0.02s - loss: 10.57546 - acc: 1.0 - batches: 7\n",
      "Epoch 418/500 - 0.02s - loss: 10.575439 - acc: 1.0 - batches: 7\n",
      "Epoch 419/500 - 0.01s - loss: 10.5754175 - acc: 1.0 - batches: 7\n",
      "Epoch 420/500 - 0.01s - loss: 10.575397 - acc: 1.0 - batches: 7\n",
      "Epoch 421/500 - 0.01s - loss: 10.5753765 - acc: 1.0 - batches: 7\n",
      "Epoch 422/500 - 0.02s - loss: 10.575356 - acc: 1.0 - batches: 7\n",
      "Epoch 423/500 - 0.01s - loss: 10.575336 - acc: 1.0 - batches: 7\n",
      "Epoch 424/500 - 0.01s - loss: 10.575315 - acc: 1.0 - batches: 7\n",
      "Epoch 425/500 - 0.02s - loss: 10.575295 - acc: 1.0 - batches: 7\n",
      "Epoch 426/500 - 0.02s - loss: 10.575275 - acc: 1.0 - batches: 7\n",
      "Epoch 427/500 - 0.02s - loss: 10.575256 - acc: 1.0 - batches: 7\n",
      "Epoch 428/500 - 0.01s - loss: 10.575236 - acc: 1.0 - batches: 7\n",
      "Epoch 429/500 - 0.02s - loss: 10.575217 - acc: 1.0 - batches: 7\n",
      "Epoch 430/500 - 0.01s - loss: 10.575199 - acc: 1.0 - batches: 7\n",
      "Epoch 431/500 - 0.02s - loss: 10.575182 - acc: 1.0 - batches: 7\n",
      "Epoch 432/500 - 0.02s - loss: 10.575164 - acc: 1.0 - batches: 7\n",
      "Epoch 433/500 - 0.01s - loss: 10.575145 - acc: 1.0 - batches: 7\n",
      "Epoch 434/500 - 0.02s - loss: 10.575127 - acc: 1.0 - batches: 7\n",
      "Epoch 435/500 - 0.02s - loss: 10.57511 - acc: 1.0 - batches: 7\n",
      "Epoch 436/500 - 0.01s - loss: 10.575093 - acc: 1.0 - batches: 7\n",
      "Epoch 437/500 - 0.01s - loss: 10.575077 - acc: 1.0 - batches: 7\n",
      "Epoch 438/500 - 0.01s - loss: 10.57506 - acc: 1.0 - batches: 7\n",
      "Epoch 439/500 - 0.01s - loss: 10.575043 - acc: 1.0 - batches: 7\n",
      "Epoch 440/500 - 0.02s - loss: 10.575027 - acc: 1.0 - batches: 7\n",
      "Epoch 441/500 - 0.02s - loss: 10.575012 - acc: 1.0 - batches: 7\n",
      "Epoch 442/500 - 0.02s - loss: 10.574995 - acc: 1.0 - batches: 7\n",
      "Epoch 443/500 - 0.02s - loss: 10.574981 - acc: 1.0 - batches: 7\n",
      "Epoch 444/500 - 0.02s - loss: 10.574966 - acc: 1.0 - batches: 7\n",
      "Epoch 445/500 - 0.02s - loss: 10.574951 - acc: 1.0 - batches: 7\n",
      "Epoch 446/500 - 0.02s - loss: 10.574937 - acc: 1.0 - batches: 7\n",
      "Epoch 447/500 - 0.02s - loss: 10.574923 - acc: 1.0 - batches: 7\n",
      "Epoch 448/500 - 0.02s - loss: 10.574907 - acc: 1.0 - batches: 7\n",
      "Epoch 449/500 - 0.02s - loss: 10.574894 - acc: 1.0 - batches: 7\n",
      "Epoch 450/500 - 0.02s - loss: 10.574881 - acc: 1.0 - batches: 7\n",
      "Epoch 451/500 - 0.01s - loss: 10.574865 - acc: 1.0 - batches: 7\n",
      "Epoch 452/500 - 0.01s - loss: 10.574852 - acc: 1.0 - batches: 7\n",
      "Epoch 453/500 - 0.01s - loss: 10.57484 - acc: 1.0 - batches: 7\n",
      "Epoch 454/500 - 0.02s - loss: 10.574827 - acc: 1.0 - batches: 7\n",
      "Epoch 455/500 - 0.01s - loss: 10.574813 - acc: 1.0 - batches: 7\n",
      "Epoch 456/500 - 0.02s - loss: 10.5748 - acc: 1.0 - batches: 7\n",
      "Epoch 457/500 - 0.01s - loss: 10.574787 - acc: 1.0 - batches: 7\n",
      "Epoch 458/500 - 0.02s - loss: 10.574776 - acc: 1.0 - batches: 7\n",
      "Epoch 459/500 - 0.02s - loss: 10.574763 - acc: 1.0 - batches: 7\n",
      "Epoch 460/500 - 0.02s - loss: 10.574751 - acc: 1.0 - batches: 7\n",
      "Epoch 461/500 - 0.02s - loss: 10.5747385 - acc: 1.0 - batches: 7\n",
      "Epoch 462/500 - 0.02s - loss: 10.574726 - acc: 1.0 - batches: 7\n",
      "Epoch 463/500 - 0.01s - loss: 10.574715 - acc: 1.0 - batches: 7\n",
      "Epoch 464/500 - 0.01s - loss: 10.574702 - acc: 1.0 - batches: 7\n",
      "Epoch 465/500 - 0.02s - loss: 10.57469 - acc: 1.0 - batches: 7\n",
      "Epoch 466/500 - 0.01s - loss: 10.574679 - acc: 1.0 - batches: 7\n",
      "Epoch 467/500 - 0.02s - loss: 10.574667 - acc: 1.0 - batches: 7\n",
      "Epoch 468/500 - 0.02s - loss: 10.5746565 - acc: 1.0 - batches: 7\n",
      "Epoch 469/500 - 0.01s - loss: 10.574646 - acc: 1.0 - batches: 7\n",
      "Epoch 470/500 - 0.02s - loss: 10.574635 - acc: 1.0 - batches: 7\n",
      "Epoch 471/500 - 0.02s - loss: 10.574624 - acc: 1.0 - batches: 7\n",
      "Epoch 472/500 - 0.01s - loss: 10.5746155 - acc: 1.0 - batches: 7\n",
      "Epoch 473/500 - 0.02s - loss: 10.574605 - acc: 1.0 - batches: 7\n",
      "Epoch 474/500 - 0.01s - loss: 10.5745945 - acc: 1.0 - batches: 7\n",
      "Epoch 475/500 - 0.01s - loss: 10.574585 - acc: 1.0 - batches: 7\n",
      "Epoch 476/500 - 0.02s - loss: 10.574574 - acc: 1.0 - batches: 7\n",
      "Epoch 477/500 - 0.02s - loss: 10.574566 - acc: 1.0 - batches: 7\n",
      "Epoch 478/500 - 0.01s - loss: 10.574554 - acc: 1.0 - batches: 7\n",
      "Epoch 479/500 - 0.02s - loss: 10.574546 - acc: 1.0 - batches: 7\n",
      "Epoch 480/500 - 0.02s - loss: 10.574537 - acc: 1.0 - batches: 7\n",
      "Epoch 481/500 - 0.01s - loss: 10.57453 - acc: 1.0 - batches: 7\n",
      "Epoch 482/500 - 0.01s - loss: 10.57452 - acc: 1.0 - batches: 7\n",
      "Epoch 483/500 - 0.01s - loss: 10.574511 - acc: 1.0 - batches: 7\n",
      "Epoch 484/500 - 0.01s - loss: 10.574503 - acc: 1.0 - batches: 7\n",
      "Epoch 485/500 - 0.01s - loss: 10.574495 - acc: 1.0 - batches: 7\n",
      "Epoch 486/500 - 0.02s - loss: 10.574486 - acc: 1.0 - batches: 7\n",
      "Epoch 487/500 - 0.02s - loss: 10.574478 - acc: 1.0 - batches: 7\n",
      "Epoch 488/500 - 0.02s - loss: 10.57447 - acc: 1.0 - batches: 7\n",
      "Epoch 489/500 - 0.02s - loss: 10.574462 - acc: 1.0 - batches: 7\n",
      "Epoch 490/500 - 0.02s - loss: 10.574453 - acc: 1.0 - batches: 7\n",
      "Epoch 491/500 - 0.02s - loss: 10.574446 - acc: 1.0 - batches: 7\n",
      "Epoch 492/500 - 0.02s - loss: 10.574439 - acc: 1.0 - batches: 7\n",
      "Epoch 493/500 - 0.02s - loss: 10.574431 - acc: 1.0 - batches: 7\n",
      "Epoch 494/500 - 0.02s - loss: 10.574424 - acc: 1.0 - batches: 7\n",
      "Epoch 495/500 - 0.02s - loss: 10.574417 - acc: 1.0 - batches: 7\n",
      "Epoch 496/500 - 0.02s - loss: 10.574411 - acc: 1.0 - batches: 7\n",
      "Epoch 497/500 - 0.02s - loss: 10.574404 - acc: 1.0 - batches: 7\n",
      "Epoch 498/500 - 0.02s - loss: 10.574397 - acc: 1.0 - batches: 7\n",
      "Epoch 499/500 - 0.02s - loss: 10.574391 - acc: 1.0 - batches: 7\n",
      "Epoch 500/500 - 0.02s - loss: 10.574386 - acc: 1.0 - batches: 7\n"
     ]
    }
   ],
   "source": [
    "# actual content is inside description column\n",
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"description\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "    \n",
    "# we can also use sentence detector here \n",
    "# if we want to train on and get predictions for each sentence# downloading pretrained embeddings\n",
    "use = BertSentenceEmbeddings.pretrained('sent_small_bert_L8_512')\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence_embeddings\")\n",
    "# the classes/labels/categories are in category column\n",
    "classsifierdl = ClassifierDLApproach()\\\n",
    "    .setInputCols([\"sentence_embeddings\"])\\\n",
    "    .setOutputCol(\"class\")\\\n",
    "    .setLabelColumn(\"category\")\\\n",
    "    .setMaxEpochs(500)\\\n",
    "    .setBatchSize(32)\\\n",
    "    .setRandomSeed(0)\\\n",
    "    .setEnableOutputLogs(True)\\\n",
    "    .setOutputLogsPath('classifer_logs')\\\n",
    "\n",
    "use_clf_pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        use,\n",
    "        classsifierdl\n",
    "    ])\n",
    "\n",
    "use_pipelineModel = use_clf_pipeline.fit(trainDataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea4a3607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "df = use_pipelineModel.transform(testDataset).select(\"category\",\"description\",\"class\").toPandas()\n",
    "df['result']=df['class'].apply(lambda x: x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b50095a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pipelineModel.stages[2].write().overwrite().save('Text_Classification_Bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "56923ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions =  use_pipelineModel.transform(testDataset)\n",
    "#predictions.select(\"category\", \"text\", \"class.result\").show(5, truncate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1ba9cf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_small_bert_L8_512 download started this may take some time.\n",
      "Approximate size to download 149.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# actual content is inside description column\n",
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"description\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "    \n",
    "# we can also use sentence detector here \n",
    "# if we want to train on and get predictions for each sentence# downloading pretrained embeddings\n",
    "use = BertSentenceEmbeddings.pretrained('sent_small_bert_L8_512')\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence_embeddings\")\n",
    "# the classes/labels/categories are in category column\n",
    "loaded_ner_model = ClassifierDLModel.load(\"Text_Classification_Bert\")\\\n",
    "  .setInputCols([\"sentence_embeddings\"])\\\n",
    "  .setOutputCol(\"class\")\n",
    "\n",
    "use_clf_pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        use,\n",
    "        loaded_ner_model\n",
    "    ])\n",
    "\n",
    "#use_pipelineModel = use_clf_pipeline.fit(trainDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7d70458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'document': ['navigate to kitchen'], 'sentence_embeddings': ['navigate to kitchen'], 'class': ['NAV']}\n",
      "['NAV']\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.base import LightPipeline\n",
    "#clf_pipelineModel = use_clf_pipeline.fit(trainDataset)\n",
    "\n",
    "text = \"navigate to kitchen\"\n",
    "prediction_data = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "prediction_model = use_clf_pipeline.fit(prediction_data)\n",
    "light = LightPipeline(prediction_model)\n",
    "results = light.annotate(text)\n",
    "print(results)\n",
    "print(results['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c39d6145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SD']\n",
      "['SD']\n",
      "['CC']\n",
      "['NAV']\n",
      "['LR']\n",
      "['DA']\n",
      "['AR']\n",
      "['NAV']\n",
      "['NAV']\n"
     ]
    }
   ],
   "source": [
    "text = input(\"Enter Testing Text\\n\")\n",
    "while(text != \"exit\"):\n",
    "    results = light.annotate(text)\n",
    "    print(results['class'])\n",
    "    text = input(\"Enter New Text\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8da94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2243226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f123c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e5299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544efb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b92a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d208a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a21197b13add4b6c4ce7cb24d3cb94b238afe3cb21fedcec323a08881ade42e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
