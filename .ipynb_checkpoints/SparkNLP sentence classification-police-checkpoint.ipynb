{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e810749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "spark = sparknlp.start() \n",
    "# sparknlp.start(gpu=True) >> for training on GPUfrom sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f12d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d44868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9fa35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = spark.read \\\n",
    "      .option(\"header\", True) \\\n",
    "      .csv(\"text_train.csv\")\n",
    "trainDataset.show(10, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69940fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "trainDataset.groupBy(\"category\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1ded33",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = spark.read \\\n",
    "      .option(\"header\", True) \\\n",
    "      .csv(\"text_test.csv\")\n",
    "testDataset.groupBy(\"category\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e763ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual content is inside description column\n",
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"description\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "    \n",
    "# we can also use sentence detector here \n",
    "# if we want to train on and get predictions for each sentence# downloading pretrained embeddings\n",
    "use = UniversalSentenceEncoder.pretrained()\\\n",
    " .setInputCols([\"document\"])\\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "# the classes/labels/categories are in category column\n",
    "classsifierdl = ClassifierDLApproach()\\\n",
    "    .setInputCols([\"sentence_embeddings\"])\\\n",
    "    .setOutputCol(\"class\")\\\n",
    "    .setLabelColumn(\"category\")\\\n",
    "    .setMaxEpochs(50)\\\n",
    "    .setLr(0.003)\\\n",
    "    .setBatchSize(32)\\\n",
    "    .setRandomSeed(0)\\\n",
    "    .setVerbose(1)\\\n",
    "    .setValidationSplit(0.2)\\\n",
    "    .setEvaluationLogExtended(True) \\\n",
    "    .setEnableOutputLogs(True)\\\n",
    "    .setIncludeConfidence(True)\\\n",
    "    .setOutputLogsPath('classifer_logs')\\\n",
    "\n",
    "use_clf_pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        use,\n",
    "        classsifierdl\n",
    "    ])\n",
    "\n",
    "use_pipelineModel = use_clf_pipeline.fit(trainDataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50095a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pipelineModel.stages[2].write().overwrite().save('Text_Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba9cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual content is inside description column\n",
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"description\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "    \n",
    "# we can also use sentence detector here \n",
    "# if we want to train on and get predictions for each sentence# downloading pretrained embeddings\n",
    "use = UniversalSentenceEncoder.pretrained()\\\n",
    " .setInputCols([\"document\"])\\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "# the classes/labels/categories are in category column\n",
    "loaded_ner_model = ClassifierDLModel.load(\"Text_Classification\")\\\n",
    "  .setInputCols([\"sentence_embeddings\"])\\\n",
    "  .setOutputCol(\"class\")\n",
    "\n",
    "use_clf_pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        use,\n",
    "        loaded_ner_model\n",
    "    ])\n",
    "\n",
    "#use_pipelineModel = use_clf_pipeline.fit(trainDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f89156c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import LightPipeline\n",
    "#clf_pipelineModel = use_clf_pipeline.fit(trainDataset)\n",
    "\n",
    "text = \"navigate to kitchen\"\n",
    "prediction_data = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "prediction_model = use_clf_pipeline.fit(prediction_data)\n",
    "light = LightPipeline(prediction_model)\n",
    "results = light.annotate(text)\n",
    "print(results)\n",
    "print(results['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39d6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = input(\"Enter Testing Text\\n\")\n",
    "while(text != \"exit\"):\n",
    "    results = light.annotate(text)\n",
    "    print(results['class'])\n",
    "    text = input(\"Enter New Text\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8da94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2243226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f123c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e5299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544efb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b92a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d208a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
