{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e810749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 16:15:27 WARN Utils: Your hostname, Vader resolves to a loopback address: 127.0.1.1; using 192.168.1.94 instead (on interface enp5s0f0)\n",
      "23/01/20 16:15:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/home/sjhjrok/anaconda3/envs/NLP/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/sjhjrok/.ivy2/cache\n",
      "The jars for the packages stored in: /home/sjhjrok/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-3a2e3506-a4ec-4a11-9205-1042d32dc04d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;4.2.2 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
      "\tfound net.jcip#jcip-annotations;1.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.21 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.3 in central\n",
      ":: resolution report :: resolve 215ms :: artifacts dl 10ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;4.2.2 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.3 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   17  |   0   |   0   |   0   ||   17  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-3a2e3506-a4ec-4a11-9205-1042d32dc04d\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 17 already retrieved (0kB/6ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 16:15:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 16:15:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/01/20 16:15:29 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/01/20 16:15:29 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "Spark NLP version 4.2.2\n",
      "Apache Spark version: 3.3.1\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "spark = sparknlp.start() \n",
    "# sparknlp.start(gpu=True) >> for training on GPUfrom sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f12d71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-20 16:15:31--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8001::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24032125 (23M) [text/plain]\n",
      "Saving to: ‘news_category_train.csv.2’\n",
      "\n",
      "news_category_train 100%[===================>]  22.92M  79.6MB/s    in 0.3s    \n",
      "\n",
      "2023-01-20 16:15:31 (79.6 MB/s) - ‘news_category_train.csv.2’ saved [24032125/24032125]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#! wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d44868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-20 16:15:32--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8003::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1504408 (1.4M) [text/plain]\n",
      "Saving to: ‘news_category_test.csv.3’\n",
      "\n",
      "news_category_test. 100%[===================>]   1.43M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2023-01-20 16:15:32 (25.1 MB/s) - ‘news_category_test.csv.3’ saved [1504408/1504408]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#! wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c9fa35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------------------------------+\n",
      "|category|                                       description|\n",
      "+--------+--------------------------------------------------+\n",
      "|Business| Short sellers, Wall Street's dwindling band of...|\n",
      "|Business| Private investment firm Carlyle Group, which h...|\n",
      "|Business| Soaring crude prices plus worries about the ec...|\n",
      "|Business| Authorities have halted oil export flows from ...|\n",
      "|Business| Tearaway world oil prices, toppling records an...|\n",
      "|Business| Stocks ended slightly higher on Friday but sta...|\n",
      "|Business| Assets of the nation's retail money market mut...|\n",
      "|Business| Retail sales bounced back a bit in July, and n...|\n",
      "|Business|\" After earning a PH.D. in Sociology, Danny Baz...|\n",
      "|Business| Short sellers, Wall Street's dwindling  band o...|\n",
      "+--------+--------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDataset = spark.read \\\n",
    "      .option(\"header\", True) \\\n",
    "      .csv(\"news_category_train.csv\")\n",
    "trainDataset.show(10, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69940fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|category|count|\n",
      "+--------+-----+\n",
      "|   World|30000|\n",
      "|Sci/Tech|30000|\n",
      "|  Sports|30000|\n",
      "|Business|30000|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "trainDataset.groupBy(\"category\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1ded33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|category|count|\n",
      "+--------+-----+\n",
      "|   World| 1900|\n",
      "|Sci/Tech| 1900|\n",
      "|  Sports| 1900|\n",
      "|Business| 1900|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDataset = spark.read \\\n",
    "      .option(\"header\", True) \\\n",
    "      .csv(\"news_category_test.csv\")\n",
    "testDataset.groupBy(\"category\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e763ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[ | ]tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "Download done! Loading the resource.\n",
      "[ — ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 16:15:44.781387: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/home/sjhjrok/anaconda3/envs/NLP/lib/python3.9/site-packages/pyspark/jars/spark-core_2.12-3.3.1.jar) to field java.lang.ref.Reference.referent\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 16:16:09.990638: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/89b7f0185067_classifier_dl8683341604223767373\n",
      "2023-01-20 16:16:10.017601: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-01-20 16:16:10.017631: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/89b7f0185067_classifier_dl8683341604223767373\n",
      "2023-01-20 16:16:10.282381: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-01-20 16:16:10.683363: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/89b7f0185067_classifier_dl8683341604223767373\n",
      "2023-01-20 16:16:10.782486: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 791859 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 5 - learning_rate: 0.005 - batch_size: 64 - training_examples: 120000 - classes: 4\n",
      "Epoch 1/5 - 6.09s - loss: 1617.2489 - acc: 0.88115 - batches: 1875\n",
      "Epoch 2/5 - 5.78s - loss: 1605.1769 - acc: 0.892725 - batches: 1875\n",
      "Epoch 3/5 - 5.89s - loss: 1594.5729 - acc: 0.8978583 - batches: 1875\n",
      "Epoch 4/5 - 5.59s - loss: 1587.5382 - acc: 0.90159166 - batches: 1875\n",
      "Epoch 5/5 - 5.78s - loss: 1581.6846 - acc: 0.9041833 - batches: 1875\n"
     ]
    }
   ],
   "source": [
    "# actual content is inside description column\n",
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"description\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "    \n",
    "# we can also use sentence detector here \n",
    "# if we want to train on and get predictions for each sentence# downloading pretrained embeddings\n",
    "use = UniversalSentenceEncoder.pretrained()\\\n",
    " .setInputCols([\"document\"])\\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "# the classes/labels/categories are in category column\n",
    "classsifierdl = ClassifierDLApproach()\\\n",
    "  .setInputCols([\"sentence_embeddings\"])\\\n",
    "  .setOutputCol(\"class\")\\\n",
    "  .setLabelColumn(\"category\")\\\n",
    "  .setMaxEpochs(5)\\\n",
    "  .setEnableOutputLogs(True)\n",
    "use_clf_pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        use,\n",
    "        classsifierdl\n",
    "    ])\n",
    "\n",
    "use_pipelineModel = use_clf_pipeline.fit(trainDataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:=========>                                                (1 + 5) / 6]\r"
     ]
    }
   ],
   "source": [
    "from sparknlp.base import LightPipeline\n",
    "clf_pipelineModel = use_clf_pipeline.fit(trainDataset)\n",
    "\n",
    "light_model = LightPipeline(clf_pipelineModel)\n",
    "text=\"Euro 2020 and the Copa America have both been moved to the summer of 2021 due to the coronavirus outbreak.\"\n",
    "light_model.annotate(text)['class'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39d6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Euro 2020 and the Copa America have both been moved to the summer of 2021 due to the coronavirus outbreak.\"\n",
    "light_model.annotate(text)['class'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8da94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2243226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f123c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e5299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544efb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b92a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d208a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
